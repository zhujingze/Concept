#data
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer

class QuizDataset(Dataset):
    def __init__(self, csv_file, tokenizer_name, max_length=128):
        # 加载数据
        self.data = []
        with open(csv_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                self.data.append(row)

        # 初始化分词器
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        self.max_length = max_length
        self.label_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data[idx]
        question = row["Question"]
        options = [row["OptionA"], row["OptionB"], row["OptionC"], row["OptionD"]]
        correct_answer = self.label_mapping[row["Answer"]]

        # 将问题和每个选项组合起来，进行分词
        encodings = self.tokenizer(
            [f"{question} {option}" for option in options],
            padding="max_length",
            truncation=True,
            max_length=self.max_length,
            return_tensors="pt"
        )

        # 将标签作为目标
        return {
            "input_ids": encodings["input_ids"],       # shape: (4, max_length)
            "attention_mask": encodings["attention_mask"],  # shape: (4, max_length)
            "label": correct_answer                   # 正确答案的索引
        }

# 假设你的 CSV 文件是 'questions.csv'
csv_file = 'questions.csv'
tokenizer_name = 'bert-base-uncased'

dataset = QuizDataset(csv_file, tokenizer_name)
train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)

#train
from transformers import BertForMultipleChoice, AdamW
import torch.nn.functional as F

# 初始化模型和优化器
model = BertForMultipleChoice.from_pretrained("bert-base-uncased")
optimizer = AdamW(model.parameters(), lr=1e-5)

# 训练循环
for epoch in range(3):  # 假设训练 3 个 epoch
    model.train()
    for batch in train_dataloader:
        optimizer.zero_grad()

        # 获取输入数据
        input_ids = batch["input_ids"]        # shape: (batch_size, 4, max_length)
        attention_mask = batch["attention_mask"]  # shape: (batch_size, 4, max_length)
        labels = batch["label"]              # shape: (batch_size,)

        # 前向传播
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )

        # 损失值和反向传播
        loss = outputs.loss
        loss.backward()
        optimizer.step()

        print(f"Loss: {loss.item()}")

import torch
import pandas as pd
from torch.utils.data import Dataset
from transformers import AutoTokenizer

class MathProblemDataset(Dataset):
    def __init__(self, csv_file, tokenizer, max_length=512):
        # 读取 CSV 文件
        self.data = pd.read_csv(csv_file)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # 获取问题和选项
        question = self.data.iloc[idx, 0]  # 第 1 列是问题
        option_a = self.data.iloc[idx, 1]  # 第 2 列是选项 A
        option_b = self.data.iloc[idx, 2]  # 第 3 列是选项 B
        option_c = self.data.iloc[idx, 3]  # 第 4 列是选项 C
        option_d = self.data.iloc[idx, 4]  # 第 5 列是选项 D
        correct_answer = self.data.iloc[idx, 5]  # 第 6 列是正确答案（A/B/C/D）

        # 合并问题和选项作为输入
        input_text = f"Question: {question} A: {option_a} B: {option_b} C: {option_c} D: {option_d}"
        
        # 对输入文本进行编码
        encoded_input = self.tokenizer(input_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors="pt")

        # 将答案转换为整数标签（A -> 0, B -> 1, C -> 2, D -> 3）
        answer_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
        label = answer_map.get(correct_answer, -1)  # 如果答案不在字典里，返回 -1（处理异常）

        # 由于返回的是字典，需要从字典中取出tensor
        return encoded_input['input_ids'].squeeze(0), encoded_input['attention_mask'].squeeze(0), torch.tensor(label)


class MultipleChoiceDataset(Dataset):
    def __init__(self, csv_file, tokenizer, max_length=512):
        """
        Args:
            csv_file (str): The path to the CSV file containing the data.
            tokenizer (transformers.PreTrainedTokenizer): The tokenizer to tokenize the text.
            max_length (int): The maximum sequence length.
        """
        self.data = pd.read_csv(csv_file, header=None)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.choices = ["A", "B", "C", "D"]  # The choices in the question

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # Get the question and choices
        question = self.data.iloc[idx, 0]
        choices = [self.data.iloc[idx, i+1] for i in range(4)]
        answer = self.data.iloc[idx, 5]  # Assuming the answer is in the last column
        
        # Format the input text for the multiple-choice question
        input_text = f"Question: {question}\n"
        for i, choice in enumerate(choices):
            input_text += f"{self.choices[i]}. {choice}\n"
        
        # Tokenize the input text and truncate to max_length
        encoding = self.tokenizer(
            input_text,
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        # Get the label index (which choice is correct)
        label = self.choices.index(answer)
        
        # Convert to tensors
        return {
            'input_ids': encoding['input_ids'].squeeze(),  # Remove the batch dimension
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(label)
        }

<s>
<<SYS>>
You are a helpful assistant that answers multiple-choice questions accurately.
</SYS>

[INST] Please answer the following multiple-choice question. [/INST]

Question: What is the capital of France?  
A. Berlin  
B. Paris  
C. Madrid  
D. Rome  

Answer: 
</s>

Read the following passage and questions, then choose the right answer from options, the answer should be one of A, B, C, D.

<passage>:
"I planted a seed. Finally grow fruits. Today is a great day. Pick off the star for you. Pick off the moon for you. Let it rise for you every day. Become candles burning myself. Just light you up, hey!... You are my little little apple. How much I love you, still no enough."
This words are from the popular song You Are My Little Dear Apple. Bae Seul-Ki acted as the leading dancer in the MV of the song. She loves dancing. She became crazy about hip-hop when she was a school girl.
Bai Seul-Ki was born on September 27, 1986. She is a South Korean singer and dancer. She is 168cm tall. She loves cooking. Her favourite food is spicy and salty. She like pink and red most. There are five members in her family---father, mother, two younger brothers and herself. She isn't married.
After her father and mother broke up, she lived with her mother and new daddy. She enjoys being alone.

<question>:
Bae Seul-Ki   _   in the MV of the song according to the passage.

<options>:
A sang
B danced
C cried
D laughed

<answer>:


